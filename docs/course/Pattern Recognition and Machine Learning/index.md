# 模式识别与机器学习
## 绪论
什么是机器学习？答：本质是寻找一个函数f，构建从输入空间到概念空间的映射

## 模式识别与机器学习系统概论
### 2.1 模式识别与机器学习系统的定义
系统：具有特定功能的有机整体

模式识别与机器学习系统：结合硬件和软件，对数据中存在的物体、行为、现象等模式通用规律进行检测、描述、判别与回归的系统。

模式识别与机器学习系统通常包括：

#### 2.2.1 从0到1搭建一个分类系统

1. 数据获取、数据标注（一般是人工标注）
2. 预处理：前景分割、均值归一化、几何变换、滤波去噪
3. 特征提取与选择：可以组合利用
4. 学习器设计（分类器设计）
    - 最近邻法(learest labour)：计算最近的距离（距离：不一定是欧氏距离，是定义在希尔伯特空间上……）
    - K近邻分类：利用最接近的K个样本来预测（K小了，方差大；K大了，偏差大）
5. 应用部署

#### 2.2.2 从0到1搭建一个回归系统
回归：连续值；分类：离散问题

唯一区别：分类器换成了   

模型训练：

- 模型
- 损失函数 

### 2.2 模式识别与机器学习系统的构成

过拟合：训练集误差特别小，测试集误差特别大

如何规避：$E(w)=\frac{1}{2}\sum_{n=1}^{N}{[y(x_{n},w)-t_{n}]^{2}}+\frac{\lambda}{2}||w||^{2}$

### 2.3 模型与算法的评估、选择与优化

- 经验误差：模型在训练集上的误差，也称作训练误差；
- 泛化误差：模型在新样本上的误差，也称作测试误差
- 经验误差的意义：
    - 反映了问题的难易程度
    - 反映了学习器的拟合能力
- 泛化误差的意义：
    - 泛化误差

   
## 重点

1. 模式识别概念、系统构成、方法种类（统计、生成式……）、类型（无监督、半监督……）

2. 如何评估一个系统：查全率、查准率、曲线……

3. 验证方法：留一法、交叉验证……

4. 曲线拟合：多项式拟合、线性回归

5. FLDA

6. 感知机

7. logistic回归

8. 二值交叉熵

9. 支持向量机

10. BP反传

11. 核方法

12. 贝叶斯、最大似然、正态分布条件下的贝叶斯

13. 概率密度函数的估计：参数化方法（最大似然估计、贝叶斯估计）、非参数化(parthon窗、k近邻)

14. 决策树（信息增益、基尼模型）

15. 概率图模型（了解，不考）

16. 集成学习基本思想和概念

17. k-means:EM思想

18. PCA重要

19. 卷积神经网络（重点）（auto encoder）、循环神经网络

## 考试详细重点
- 什么是模式识别
    - 模式（Pattern）：存在于时间与空间中具有**可观测性**、**可度量性**和**可区分性**的信息。
    - 识别（Recognition）：对模式进行分析与处理，进而实现描述、辨识、分类与解释。

- 系统
    - 系统的定义：
        - 系统：系统是由相互作用相互依赖的若干组成部分结合而成的，具有特定功能的有机整体，而且这个有机整体又是它从属的更大系统的组成部分。（钱学森）
        - 模式识别与机器学习系统：结合硬件与软件，对数据中存在的物体、行为、现象等模式通用规律进行检测、描述、判别与回归的系统，通常包括原始数据获取和预处理、特征提取、分类或决策、应用与部署等步骤。
    - 系统的构成（重点）：
        - 通常由数据获取、预处理、特征提取与选择、学习器设计与部署等环节构成
        - 部署前：数据获取->预处理->特征提取与选择->学习器设计->部署
        - 部署后：输入->预处理->特征提取与选择->决策->输出
        - 分类系统与回归系统
            - 分类系统：以K近邻法为例
                - 缺点：
                    - 储存空间要求高（需要存储每一个训练样本）
                    - 距离计算复杂（距离的选择、高位空间的计算）
                    - K值带来影响（K太小，方差大，因为对数据太敏感，容易被噪声影响。K太大，偏差大，因为更依赖周围点本身的分布）
                    - 需要对K进行调参
                - 优点：
                    - 理论简单，易于实现；
                    - 不需训练，支持在线学习；
                    - 准确性高、鲁棒性好；
                    - 天然支持多分类问题。
            - 回归系统： 
    - 系统的评估
        - 构建验证集：
            - 留出法（Hold-out）：直接将数据集划分为两个互斥集合
            - K折交叉验证（Cross-Validation）：分层划分为K个互斥子集
                - 有时会采用多种（M种）划分方式，每次求交叉验证结果，再求平均，可以称为M次K折交叉验证
                - 分层采样：将数据划分为K个大小相似的互斥子集，通过分层采样让每个子集的分布尽可能一致
                - 组合方式：每次用k-1个子集的并集作为训练集，余下的子集作为验证集，共得到K组划分
                - K的取值：测试结果的稳定性与保真性取决于K，也叫作“K折交叉验证”，K通常取10
            - 自助法（Bootstrap）：有放回采样（确保训练集大小）：对样本量为n的数据集每次有放回的随机采样得到n个样本作为训练集，未被采样到的数据作为测试集
                - 优点：可解决因训练样本规模导致的偏差，对小数据集、数据难以有效划分时很有效
                - 缺点：
                    - 存在数据浪费，约1/3样本未用于训练，连续n次不中的概率： $ \lim_{n \to \infty} (1-\frac{1}{n})^{n} = \frac{1}{e} = 0.368 $
                    - 有放回采样改变了原始数据分布，会引入估计偏差
                    - 所以初始数据量较多时，留出法、交叉验证法更为常用
        - 性能度量：
            - 回归任务：均方误差
            - 分类任务：
                - 混淆矩阵： 
                    - 标签为True，预测为Positive，称为TP(true positive)
                    - 标签为False，预测为Positive，称为FP(false positive)
                    - 标签为True，预测为Negative，称为FN（false negative，注意这里易错）
                    - 标签为False，预测为Positive，称为TN（true positive，注意这里易错）
                - 查准率precision $ P = \frac{TP}{TP+FP} $，查全率Recall $ R = \frac{TP}{TP+FN} $
                - P-R曲线：根据学习器的预测结果按正例可能性大小对样例进行排序，并逐个把样本作为正例进行预测，则可以得到查准率-查全率曲线，简称“P-R曲线”
                    - 平衡点 (BEP, Break-Even Point)是曲线上“查准率=查全率”时的取值，可用来用于度量P-R曲线有交叉的分类器性能高低
                - ROC曲线：以“假正例率FPR”为横轴，“真正例率TPR”

- PCA（Principle Component Analysis）
    - 

- 卷积神经网络
    - 网络正则化：
        - 提前停止： Early Stopping
        - 权重衰减： Weight Decay
        - 丢弃法： Dropout
        - 网络结构： Network Structure
    - CNN：
        - Zero padding：补零