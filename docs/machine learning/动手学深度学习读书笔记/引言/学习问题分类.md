## 监督学习
适用类型：在给定输入特征的情况下预测标签（每个“特征-标签”对称为一个样本）

问题描述：在给定一组特定的可用数据的情况下，估计未知事物的概率

目标：生成一个模型，能够将任何输入特征映射到标签（预测）

步骤：
![](https://zh-v2.d2l.ai/_images/supervised-learning.svg)

### 回归
问题描述：有关“有多少”的问题

数据：标签为任意数值

模型：回归函数，输出为数值

目标函数：平方误差损失函数

### 分类
问题描述：预测样本属于哪个类别（“哪一个”）

问题类型：

+ 二项分类：只有两类的最简单的分类问题
+ 多项分类：具有两个以上类别的分类问题
+ 层次分类：寻找层次结构（分类错误不均等）

分类预测刻画：给定一个样本特征，模型为每个可能的类分配一个概率；预测类别概率的大小传达了一种模型的不确定性

模型：分类器，输出为预测的类别

目标函数：交叉熵损失函数

> 最常见的类别不一定是最终用于决策的类别，当不确定风险远远大于收益时，将预期风险作为损失函数


### 标记
问题类型：

+ 多标签分类：学习预测不互相排斥类别的问题

### 搜索
问题描述：检索相关性分数最高的部分结果，并对搜索结果进行排序

### 推荐系统
目标：向特定用户进行“个性化”推荐，为给定用户和物品的匹配性打分，从而检索得分最高的对象集，将其推荐给用户

### 序列学习
特点：

+ 具有“记忆”功能
+ 输入、输出都是长度可变的序列

问题类型：

+ 标记和解析：基于结构和语法假设对文本进行分解和注释，以获得一些注释
+ 自动语音识别：输入说话人的录音，输出所说内容的文本记录
+ 文本到语音
+ 机器翻译
+ 二维布局分析
+ 对话问题

## 无监督学习
问题描述：数据中不含有“目标”的机器学习问题

问题类型：

+ 聚类：在没有标签的情况下对数据分类
+ 主成分分析：找到少量的参数来准确捕捉数据的线性相关属性
+ 因果关系 / 概率图模型：描述观察到的许多数据的根本原因
+ 生成对抗网络：利用潜在的统计机制检查真实和虚假数据是否相同，以合成数据

## 强化学习
特点：与环境互动

与环境互动 VS 离线学习：

+ 离线学习：学习在算法与环境断开后进行（“预测模型”）
	+ 优势：可孤立地进行模式识别，无需考虑其他问题
	+ 缺陷：可解决的问题有限
+ 与环境互动：互动会影响环境（“智能代理”）
> 分布偏移：训练和测试数据不同

学习过程：

![](https://zh-v2.d2l.ai/_images/rl-environment.svg)

目标：产生好的策略（智能体选择的动作受策略控制；从环境观察映射到行动的功能）

通用性：

+ 监督学习 $\to$ 强化学习：智能体输出对应一个动作，并创建一个环境给予智能体奖励，奖励与损失函数一致

问题：

+ 学分分配：决定哪些行为值得奖励，哪些行为需要乘法
+ 可观测性：当前观测结果可能无法阐述有关当前状态的信息
+ 策略选择：利用当前最好的策略，还是探索新的策略空间

问题类型：

+ 马尔可夫决策过程：环境可被完全观察到
+ 上下文赌博机：状态不依赖于之前的操作
+ 多臂赌博机：没有状态，只有一组最初未知回报的可用动作
