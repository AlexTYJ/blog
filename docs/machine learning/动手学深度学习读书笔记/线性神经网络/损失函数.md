作用：量化目标的实际值与预测值之间的差距
> 通常选择非负数作为损失，数值越小损失越小，完美预测时误差为0

## 平方误差函数
定义：样本$i$预测值为$\hat{y}^{(i)}$，其对应的真实标签为$y^{(i)}$，平方误差为
$$
l^{(i)}(\mathbf w,b)=\dfrac{1}{2}\left(\hat{y}^{(i)}-y^{(i)}\right)^2
$$
![zh.d2l.ai/\_images/fit-linreg.svg](https://zh.d2l.ai/_images/fit-linreg.svg)
> 常数$\dfrac{1}{2}$使得求导后系数化为1，简化形式

推广：模型在整个数据集上的质量：训练集样本上的损失均值
$$
L(\mathbf w,b)=\dfrac{1}{n}\sum_{i=1}^nl^{(i)}(\mathbf w,b)
$$

推导：

+ 正态分布：
$$
X\sim N(\mu,\sigma^2)\Rightarrow P(X=x)=\dfrac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\dfrac{1}{2\sigma^2}(x-\mu)^2\right)
$$
+ 噪声：$y=\mathbf {w^\mathsf Tx}+b+\epsilon\qquad\epsilon\sim N(0,\sigma^2)$
+ 似然：

$$
\begin{array}{l}
L(\mathbf x^{(i)},y^{(i)};\mathbf w,b)=P(\epsilon=y^{(i)}-\mathbf{w^\mathsf Tx}^{(i)}-b)=\dfrac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\dfrac{1}{2\sigma^2}(y^{(i)}-\mathbf{w^\mathsf Tx}^{(i)}-b)^2\right)\\
L(\mathbf X,\mathbf y;\mathbf w,b)=\prod\limits_{i=1}^nL(\mathbf x^{(i)},y^{(i)};\mathbf w,b)
\end{array}
$$

+ 极大似然：最小化负对数似然（优化一般指最小化）
$$
-\ln L(\mathbf X,\mathbf y;\mathbf w,b)=\sum_{i=1}^n\dfrac{1}{2}\ln(2\pi\sigma^2)+\dfrac{1}{2\sigma^2}(y^{(i)}-\mathbf{w^\mathsf Tx}^{(i)}-b)^2
$$
> 在高斯噪声假设下，最小化均方误差 $\Leftrightarrow$ 线性模型极大似然估计

## 交叉熵损失
定义：对于任何标签$\mathbf y$和模型预测$\hat{\mathbf y}$，损失函数为
$$
l(\mathbf y,\hat{\mathbf y})=-\sum_{j=1}^qy_j\log \hat{y_j}
$$

推导：

+ 模型定义：$\hat y=P(y=1|x),\ 1-\hat y=P(y=0|x)$
+ 似然：$\hat y$为关于模型参数的函数，似然函数值为得到该预测结果的概率
$$
L(y^{(i)},\hat y_j)=P(y_j|x^{(i)})={\hat y_j}^{y_j}\cdot{(1-\hat y_j)}^{1-y_j}\quad y_j\in\set{0,1}
$$
$$
L(\mathbf y,\hat{\mathbf y})=P(\mathbf Y|\mathbf X)=\prod_{i=1}^q{\hat y_j}^{y_j}\cdot{(1-\hat y_j)}^{1-y_j}
$$
+ 极大似然：
$$
-\ln L(\mathbf y,\hat{\mathbf y})=\sum_{i=1}^nl(\mathbf y^{(i)},\hat{\mathbf y}^{(i)})
$$
> $P(\mathbf y|\mathbf x)=1$，即正确预测时损失函数不能进一步最小化，但由于标签中噪声的存在或输入特征不够而不可能完美分类

